{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torch.utils.data as data\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CocoDataset(data.Dataset):\n",
    "    \"\"\"COCO Custom Dataset compatible with torch.utils.data.DataLoader.\"\"\"\n",
    "\n",
    "    def __init__(self, root, origin_file, img_tags, vocab):\n",
    "        \"\"\"Set the path for images, captions and vocabulary wrapper.\n",
    "\n",
    "        Args:\n",
    "            root: image directory.\n",
    "            json: coco annotation file path.\n",
    "            vocab: vocabulary wrapper.\n",
    "            transform: image transformer.\n",
    "        \"\"\"\n",
    "        self.root = root\n",
    "        with open(origin_file, 'r') as j:\n",
    "            self.origin_file = json.load(j)\n",
    "        with open(img_tags, 'r') as j:\n",
    "            self.img_tags = json.load(j)\n",
    "        with open(vocab, 'r') as j:\n",
    "            self.vocab = json.load(j)\n",
    "        self.transform = transforms.Compose([\n",
    "        transforms.RandomCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.485, 0.456, 0.406),\n",
    "                             (0.229, 0.224, 0.225))])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"Returns one data pair (image and caption).\"\"\"\n",
    "\n",
    "        word2id = self.vocab['word_map']\n",
    "\n",
    "        img_id = self.origin_file['images'][index]['imgid']\n",
    "        path = self.origin_file['images'][index]['filepath'] + \\\n",
    "            '/'+self.origin_file['images'][index]['filename']\n",
    "\n",
    "        image = Image.open(os.path.join(self.root, path)).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Convert caption (string) to word ids.\n",
    "        tags = []\n",
    "        # t = list(map(str.lower, img_tags[index]))\n",
    "        tags = [word2id[token] for token in self.img_tags[str(index)]]\n",
    "        target = torch.Tensor(tags)\n",
    "        return image, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/home/lkk/datasets/coco2014'\n",
    "origin_file = root+'/'+'dataset_coco.json'\n",
    "img_tags='./img_tags.json'\n",
    "voc = './vocab.json'\n",
    "coco=CocoDataset(root,origin_file,img_tags,voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "[110, 19, 32, 12, 30, 28, 972, 234, 139, 544, 207, 50, 67, 160, 208, 514, 1, 525, 376, 84, 213, 144, 499, 892]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 2.2147,  2.2147,  2.2147,  ...,  1.5468,  1.7352,  2.1462],\n",
       "          [ 2.2147,  2.2489,  2.1804,  ...,  2.1462,  1.3927,  1.7009],\n",
       "          [ 2.0777,  2.2489,  2.2489,  ...,  1.9749,  1.7180,  1.3927],\n",
       "          ...,\n",
       "          [-1.0904, -1.1760, -0.5938,  ...,  0.2796,  0.1597,  0.4508],\n",
       "          [-1.1247, -1.4672, -0.8678,  ...,  0.4337,  0.3652,  0.5022],\n",
       "          [-0.4739, -1.0390, -1.6555,  ...,  0.5364,  0.5022,  0.5707]],\n",
       " \n",
       "         [[ 2.3936,  2.3761,  2.4111,  ..., -0.7402, -0.5126, -0.1975],\n",
       "          [ 2.3936,  2.3410,  2.3235,  ..., -0.1800, -0.7927, -0.4251],\n",
       "          [ 2.4111,  2.4111,  2.3761,  ..., -0.4076, -0.4951, -0.9328],\n",
       "          ...,\n",
       "          [-0.8803, -0.8978, -0.3200,  ...,  0.0126, -0.1099,  0.1176],\n",
       "          [-1.0028, -1.1604, -0.7402,  ...,  0.1527,  0.0651,  0.1527],\n",
       "          [-0.0049, -0.6176, -1.6155,  ...,  0.2227,  0.1702,  0.3277]],\n",
       " \n",
       "         [[ 2.5703,  2.6400,  2.6400,  ..., -0.4973,  0.1128,  0.1999],\n",
       "          [ 2.4308,  2.5529,  2.5529,  ...,  0.1128, -0.5844, -0.0615],\n",
       "          [ 2.6051,  2.6400,  2.6400,  ...,  0.0431, -0.0267, -0.7413],\n",
       "          ...,\n",
       "          [-1.7696, -1.5779, -1.0201,  ..., -0.4973, -0.6541, -0.0267],\n",
       "          [-1.5430, -1.7696, -1.1073,  ..., -0.3927, -0.4101, -0.0441],\n",
       "          [-1.2990, -1.2641, -1.5081,  ..., -0.1661, -0.1138, -0.2707]]]),\n",
       " tensor([110.,  19.,  32.,  12.,  30.,  28., 972., 234., 139., 544., 207.,  50.,\n",
       "          67., 160., 208., 514.,   1., 525., 376.,  84., 213., 144., 499., 892.]))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coco[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'iterator' object has no attribute 'next'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-d76952e2783c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'iterator' object has no attribute 'next'"
     ]
    }
   ],
   "source": [
    "a.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
